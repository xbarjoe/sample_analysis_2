{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41773957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The output of all of these blocks of code has been cleared to save space when emailing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f915e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.impute import KNNImputer\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, make_scorer, accuracy_score, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a28af6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"./known_outcome.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d204a7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6ac37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#WARNING: THE CODE IN THIS BLOCK WILL GENERATE PAIRWISE FEATURE GRAPHS DESCRIBED IN THE WRITEUP, THIS FUNCTION TAKES\n",
    "#A WHILE TO GENERATE GRAPHS FOR ALL PAIRS.\n",
    "\n",
    "combinations = itertools.combinations(data.columns, 2)\n",
    "for combo in combinations:\n",
    "    #We can immediately Isolate DataSource1_Feature 3 here because it contains the same value for all entries\n",
    "    if 'PK_ID' in combo or 'EVICTED' in combo:\n",
    "        continue\n",
    "    sns.scatterplot(x=combo[0], y=combo[1], data=data, hue='EVICTED')\n",
    "    plt.show()\n",
    "    \n",
    "#Initial thoughts: Most useful categories: LATE_PAYMENTS, SAFERENT_SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e8f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting statistical data on important features, separated by eviction status.\n",
    "print(data.query('EVICTED == 0')['TENANT_INCOME'].describe(percentiles=[]).apply(lambda x: format(x, 'f')))\n",
    "print(data.query('EVICTED == 0')['SAFERENT_SCORE'].describe(percentiles=[]).apply(lambda x: format(x, 'f')))\n",
    "print(data.query('EVICTED == 0')['LATE_PAYMENTS'].describe(percentiles=[]).apply(lambda x: format(x, 'f')))\n",
    "print('*********************************************')\n",
    "print(data.query('EVICTED == 1')['TENANT_INCOME'].describe(percentiles=[]).apply(lambda x: format(x, 'f')))\n",
    "print(data.query('EVICTED == 1')['SAFERENT_SCORE'].describe(percentiles=[]).apply(lambda x: format(x, 'f')))\n",
    "print(data.query('EVICTED == 1')['LATE_PAYMENTS'].describe(percentiles=[]).apply(lambda x: format(x, 'f')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bdaf21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Popping out Evicted field for future training & removing ID column\n",
    "evicted = data.pop('EVICTED')\n",
    "data.drop('PK_ID', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1112fe3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#One-Hot encoding the submission day variable\n",
    "day_var = pd.get_dummies(data.DAY_APP_SUBMIT,prefix='SUBMISSION_DAY')\n",
    "data = data.join(day_var)\n",
    "data.drop('DAY_APP_SUBMIT', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8f9d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac559dbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Binarizing the OWN_CAR feature.\n",
    "car_labels = {'Y':1, 'N':0}\n",
    "data.OWN_CAR = [car_labels[entry] for entry in data.OWN_CAR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c7099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Converting gender label into binary data. Only one instance currently of XNA, treating as 0 for the time being.\n",
    "#If issues arise, I'll revisit this.\n",
    "gender_labels = {'M': 1, 'F': 0, 'XNA': 0}\n",
    "data.GENDER = [gender_labels[entry] for entry in data.GENDER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1cf7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Does exactly the same thing as the dictionary assignment used for OWN_CAR, but also catches the two instances of missing data.\n",
    "def marital_filter(idx):\n",
    "    if idx == 'Y':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data.SPOUSAL_STATUS = [marital_filter(entry) for entry in data.SPOUSAL_STATUS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2c0da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Converts APT_CLASS to binary feature (Could be renamed IS_PREMIUM_APT)\n",
    "rental_type_labels = {'A':1, 'B':0}\n",
    "data.APT_CLASS = [rental_type_labels[entry] for entry in data.APT_CLASS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9162c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.isna().sum()\n",
    "#Initial thoughts on remaining missing data:\n",
    "#Saferent features: KNN Imputing\n",
    "#CREDIT pulls: KNN Imputing\n",
    "#Count occupants: Potentially drop feature due to high miss rate, although intuition says this will be a good feature.\n",
    "#As such, will probably devote additional time to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3156825b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Showing the ratio of Single parent rentals vs two-parent rentals in the orignal dataset.\n",
    "single_parent_original = len(data.query('COUNT_CHILDREN > 0').query('COUNT_OCCUPANTS == COUNT_CHILDREN + 1'))\n",
    "double_parent_original = len(data.query('COUNT_CHILDREN > 0').query('COUNT_OCCUPANTS == COUNT_CHILDREN + 2'))\n",
    "print(single_parent_original/len(data))\n",
    "print(double_parent_original/len(data))\n",
    "print(len(data.query('COUNT_CHILDREN > 0'))/len(data))\n",
    "#We can see single parents account for approx. 2% of the tennants, whereas dual parents account for approx. 11%.\n",
    "#This leaves approx. 17% of the parental status unaccounted for.\n",
    "#We'll assume this ratio holds true for the missing values and impute the missing values for properties with children on file\n",
    "#manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cf7e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac16741",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Dual parenthood is approx. 5.5x more common than single-parenthood, so we use the following function to\n",
    "#inject the expected number of parents into the missing data slots, keeping the ratio of sinlge/dual parents the same.\n",
    "def parent_ratio():\n",
    "    if(random.random() <= (single_parent_original/double_parent_original)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75556b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Given this, We'll select only the entries with children and missing occupant information, and make the two entries equal\n",
    "data.loc[(data.COUNT_CHILDREN >= 1) & (data.COUNT_OCCUPANTS.isnull()),'COUNT_OCCUPANTS'] = data.loc[(data.COUNT_CHILDREN >= 1) & (data.COUNT_OCCUPANTS.isnull()),'COUNT_CHILDREN']\n",
    "#Then, we'll probabilistically add either 1 or 2 to the occupant count (based on our ratio above)\n",
    "data.loc[(data.COUNT_CHILDREN == data.COUNT_OCCUPANTS),'COUNT_OCCUPANTS'] = data.loc[(data.COUNT_CHILDREN == data.COUNT_OCCUPANTS),'COUNT_OCCUPANTS'].apply(lambda x: x + parent_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a823ae3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Then we'll recount and ensure the ratio is approximately the same\n",
    "single_parent_new = len(data.query('COUNT_CHILDREN > 0').query('COUNT_OCCUPANTS == COUNT_CHILDREN + 1'))\n",
    "double_parent_new = len(data.query('COUNT_CHILDREN > 0').query('COUNT_OCCUPANTS == COUNT_CHILDREN + 2'))\n",
    "print(single_parent_new/len(data))\n",
    "print(double_parent_new/len(data))\n",
    "print(len(data.query('COUNT_CHILDREN > 0'))/len(data))\n",
    "#Which, within acceptable error ranges, it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8182fe77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#At this point we can use KNN to impute the rest of the data, I timed it out of curiosity.\n",
    "start = time.time()\n",
    "imputer = KNNImputer()\n",
    "imputed_data = imputer.fit_transform(data)\n",
    "original_imputed = pd.DataFrame(imputed_data,columns = data.columns)\n",
    "imputed_df = original_imputed.copy(deep = True)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226e884",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imputed_df = original_imputed.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784e16e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#We'll then convert the imputed df to a numpy array to feed into the model & information gain algorithm\n",
    "X = imputed_df.to_numpy()\n",
    "Y = evicted.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361c478",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Run mutual information gain algorithm to verify thoughts on important features and potentially highlight missed features\n",
    "#that show importance.\n",
    "information = mutual_info_classif(X, Y)\n",
    "feat_importances = pd.Series(information, imputed_df.columns[0:len(imputed_df.columns)])\n",
    "feat_importances.plot(kind='barh',color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23cc04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using K-Folds cross-validation and an 80:20 Train/Validiton split, run a simple logistic regression\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "for train, test in kfold.split(X, Y):\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=26, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['AUC'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(X[train], Y[train], epochs=100, batch_size=64, verbose=1, validation_split=0.2, callbacks=[callback])\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=1)\n",
    "    \n",
    "    #Plot the Training / Validation Loss\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60458c40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Evaluate model performance\n",
    "y_pred = model.predict(X[test])\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "cm = confusion_matrix(y_pred, Y[test])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "print(roc_auc_score(Y[test],y_pred))\n",
    "print(classification_report(Y[test],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda1c39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#We're getting relatively high training / validation accuracy, but lower testing accuracy. This usually means one of two things.\n",
    "#A: We're overfitting the data with our model\n",
    "#B: The data is not strongly predictive, in which case we won't see any accuracy gains in our attempts to reduce overfitting\n",
    "#We'll start by reducing the model complexity by eliminating features that didn't provide much value from our analysis above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f157a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28baac98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Based on the results of the information gain, we'll remove some of the less useful features\n",
    "cols_to_drop = ['SUBMISSION_DAY_SUNDAY',\n",
    "               'SUBMISSION_DAY_MONDAY',\n",
    "               'SUBMISSION_DAY_TUESDAY',\n",
    "               'SUBMISSION_DAY_WEDNESDAY',\n",
    "               'SUBMISSION_DAY_THURSDAY',\n",
    "               'SUBMISSION_DAY_FRIDAY',\n",
    "               'SUBMISSION_DAY_SATURDAY',\n",
    "               'HOUR_APP_SUBMIT',\n",
    "               'STATE_WORK_ADDRESS_MISMATCH',\n",
    "               'CREDIT_PULLS']\n",
    "reduced_df = imputed_df.drop(columns=cols_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee653254",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad472d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using the same settings as before, run a new logistic regression\n",
    "X = reduced_df.to_numpy()\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "for train, test in kfold.split(X, Y):\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=16, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['AUC'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(X[train], Y[train], epochs=100, batch_size=64, verbose=1, validation_split=0.2, callbacks=[callback])\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=1)\n",
    "    \n",
    "    #Plot the Training / Validation Loss\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092e157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X[test])\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "cm = confusion_matrix(y_pred, Y[test])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "print(roc_auc_score(Y[test],y_pred))\n",
    "print(classification_report(Y[test],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interestingly enough, we actually performed slightly worse with this model.\n",
    "#Next steps will be scaling the data to [0,1] as this can lead to performance increases with regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aebad0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Min-Max scaler with no additional parameters will scale to [0,1]\n",
    "reduced_df = imputed_df.drop(columns=cols_to_drop,axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = pd.DataFrame(scaler.fit_transform(reduced_df),columns = reduced_df.columns)\n",
    "scaled_unimputed = pd.DataFrame(scaler.fit_transform(data),columns = data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e671a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44332014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#With the same settings as before, run a scaled logistic regression\n",
    "X = scaled_data.to_numpy()\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for train, test in kfold.split(X, Y):\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=16, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['AUC'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(X[train], Y[train], epochs=100, batch_size=64, verbose=1, validation_split=0.2, callbacks=[callback])\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=1)\n",
    "    \n",
    "    #Plot the Training / Validation Loss\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e96ac1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Evaluate model performance\n",
    "y_pred = model.predict(X[test])\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "cm = confusion_matrix(y_pred, Y[test])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "print(roc_auc_score(Y[test],y_pred))\n",
    "print(accuracy_score(Y[test],y_pred))\n",
    "print(classification_report(Y[test],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b184aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The loss graphs already look way better than the previous two attempts, and the accuracy / AUC score improvements reflect this.\n",
    "#However I'd ideally like to get our metrics a little higher, as this model is still struggling with identifying positive cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2911de2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create a copy of the data that is both scaled and has uninformative features added back.\n",
    "scaled_unreduced_data = pd.DataFrame(scaler.fit_transform(imputed_df),columns = imputed_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e138e39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaled_unreduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4671a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using the same settings as before, run a final logistic regression\n",
    "X = scaled_unreduced_data.to_numpy()\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for train, test in kfold.split(X, Y):\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=26, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['AUC'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(X[train], Y[train], epochs=100, batch_size=64, verbose=1, validation_split=0.2, callbacks=[callback])\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=1)\n",
    "    \n",
    "    #Plot the Training / Validation Loss\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd19f14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Evaluate model performance.\n",
    "y_pred = model.predict(X[test])\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "cm = confusion_matrix(y_pred, Y[test])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "print(str(roc_auc_score(Y[test],y_pred)))\n",
    "print(classification_report(Y[test],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7868fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This gave us very marginal improvements to our performance metrics, so we might be approaching the limit of what logistic \n",
    "#regression can do with this data set. Next we'll try using a gradient boosting machine, as this has worked well when logistic\n",
    "#regression falls flat, in my experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d3ce0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Streamline model creation to a function for ease-of-comparisons.\n",
    "def fit_gbm(input_data,show_cm = False):\n",
    "    if(isinstance(input_data, np.ndarray)):\n",
    "        X = input_data\n",
    "    else:\n",
    "        X = input_data.to_numpy()\n",
    "    Y = evicted.to_numpy()\n",
    "    seed = 6089\n",
    "    test_size = 0.2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train, verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    if(show_cm):\n",
    "        cm = confusion_matrix(y_pred, y_test)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot()\n",
    "        plt.show()\n",
    "    print(\"Area under ROC-Curve: \"+str(roc_auc_score(y_test,y_pred)))\n",
    "    print(\"Accuracy: \"+str(accuracy_score(y_test,y_pred)))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016b053",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Train and evaluate all prior data format options through GBMs\n",
    "fit_gbm(data)\n",
    "fit_gbm(imputed_data)\n",
    "fit_gbm(scaled_data)\n",
    "fit_gbm(scaled_unreduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6ebdbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Print performance metrics for highest performing GBM\n",
    "model = fit_gbm(imputed_data,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd0ffc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#format & make predictions for unknown_outcome.csv\n",
    "unknown = pd.read_csv(r\"./unknown_outcome.csv\")\n",
    "u_id = unknown.pop('PK_ID')\n",
    "u_day_var = pd.get_dummies(unknown.DAY_APP_SUBMIT,prefix='SUBMISSION_DAY')\n",
    "unknown = unknown.join(u_day_var)\n",
    "unknown.drop('DAY_APP_SUBMIT', axis=1, inplace=True)\n",
    "unknown.GENDER = [gender_labels[entry] for entry in unknown.GENDER]\n",
    "unknown.OWN_CAR = [car_labels[entry] for entry in unknown.OWN_CAR]\n",
    "unknown.SPOUSAL_STATUS = [marital_filter(entry) for entry in unknown.SPOUSAL_STATUS]\n",
    "unknown.APT_CLASS = [rental_type_labels[entry] for entry in unknown.APT_CLASS]\n",
    "unknown.loc[(unknown.COUNT_CHILDREN >= 1) & (unknown.COUNT_OCCUPANTS.isnull()),'COUNT_OCCUPANTS'] = unknown.loc[(unknown.COUNT_CHILDREN >= 1) & (unknown.COUNT_OCCUPANTS.isnull()),'COUNT_CHILDREN']\n",
    "unknown.loc[(unknown.COUNT_CHILDREN == unknown.COUNT_OCCUPANTS),'COUNT_OCCUPANTS'] = unknown.loc[(unknown.COUNT_CHILDREN == unknown.COUNT_OCCUPANTS),'COUNT_OCCUPANTS'].apply(lambda x: x + parent_ratio())\n",
    "start = time.time()\n",
    "imputer = KNNImputer()\n",
    "unknown_imputed = imputer.fit_transform(unknown)\n",
    "unknown_imputed = pd.DataFrame(unknown_imputed,columns = data.columns)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "X = unknown_imputed.to_numpy()\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccad7404",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Add classification & ID back to unknown_outcome\n",
    "unknown_imputed.insert(loc = 0, column = 'EVICTED_PREDICTION', value = model.predict(X))\n",
    "unknown_imputed.insert(loc = 1, column = 'PK_ID', value = u_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e628cd0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unknown_imputed.query('EVICTED_PREDICTION == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c647fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unknown_imputed.to_csv(r'./unknown_outcome_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd493332",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Compare positive classification rates between true / predicted outcomes.\n",
    "data_with_class = data.copy(deep = True)\n",
    "data_with_class.insert(loc = 0, column = 'EVICTED', value = evicted)\n",
    "original_evicted = len(data_with_class.query('EVICTED == 1'))\n",
    "pred_evicted = len(unknown_imputed.query('EVICTED_PREDICTION == 1'))\n",
    "print(original_evicted / 100000)\n",
    "print(pred_evicted / 5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
